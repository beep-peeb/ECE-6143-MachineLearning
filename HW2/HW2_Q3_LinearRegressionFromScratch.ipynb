{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regresion \n",
    "## From Scratch by defining Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Data\n",
    "Import the Libraries and the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "d = X.shape[1]\n",
    "\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Representation\n",
    "Rearrange the X data to add the extra first column for w0\n",
    "\n",
    "Split the dataset into Train and Test with a 80:20 Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_column = np.ones((X.shape[0],1))\n",
    "X = np.concatenate((one_column, X), axis = 1)\n",
    "\n",
    "n = X.shape[0]\n",
    "\n",
    "X_train = X[1:int(n*0.8)]\n",
    "y_train = y[1:int(n*0.8)]\n",
    "X_test = X[int(n*0.8):,]\n",
    "y_test = y[int(n*0.8):,]\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hypothesis Function \n",
    "Create an Function for the Linear Model which will be a representation for our f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fxFunction(w, X):\n",
    "    f = np.dot(X,w.transpose())\n",
    "    f = f.reshape(X.shape[0])\n",
    "    return f \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gradient Descent Function\n",
    "Create a Gradient Descent function which will minimise the cost function and calculate the attibute matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(w,alpha,num,f,X,y,d):\n",
    "    for i in range(0,num):\n",
    "        w = w - (alpha) * (X.T.dot( (X.dot(w.T) ) - y ))\n",
    "    w = w.reshape(1,d)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Linear Regression Model Pipeline \n",
    "Multi Linear Regression function to call the Gradient Descent Function by doing valid data formating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_linear_regresion(X,y,alpha,epochs):\n",
    "    d = X.shape[1]\n",
    "    w = np.zeros(d)\n",
    "    f = fxFunction(w,X)\n",
    "    w = gradientDescent(w,alpha,epochs,f,X,y,d)\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fiting the model with the Training data Set\n",
    "Call the Linear Regression funnction created above with the valid Alpha and Number of interations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "num_itera = 1000\n",
    "\n",
    "w  = multi_linear_regresion(X_train,y_train,alpha,num_itera)\n",
    "# print(w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Prediction\n",
    "Predict the y values for the X_test data using the fxFunction by passing the \"w\" matrix created above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = fxFunction(w,X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Analysis of the predicted Values \n",
    "Calculate the r_squared error to conduct the analysis of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(y_p,y):\n",
    "    sst = np.sum((y-y.mean())**2)\n",
    "    ssr = np.sum((y_p-y)**2)\n",
    "    r2 = 1-(ssr/sst)\n",
    "    return r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_square for Linear Model from Scratch = 0.533502\n"
     ]
    }
   ],
   "source": [
    "r2_error = r2(y_pred,y_test)\n",
    "print(\"R_square for Linear Model from Scratch = {0:f}\".format(r2_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Compare using Scikit Learn \n",
    "Use Scikil Learn's Linear Regression Model to predict on the same Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Train the Scikit Learn Model on the training data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Predict on the trained Scikit Learn Linea Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_m = regr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Calculate the r_squared error value for the Scikit Learn prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_m = r2(y_pred_m,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Squared value Comparison\n",
      "Linear Model from Scratch = 0.533502\n",
      "Linear Model from Scikit Learn = 0.544478\n"
     ]
    }
   ],
   "source": [
    "print(\"R_Squared value Comparison\")\n",
    "print(\"Linear Model from Scratch = {0:f}\".format(r2_error))\n",
    "print(\"Linear Model from Scikit Learn = {0:f}\".format(r2_m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
